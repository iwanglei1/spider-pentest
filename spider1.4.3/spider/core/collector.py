# date: 2020/1/07 15:10
# author: liyong
import time
from . import const
from .soup import Soup
from .utils import print_progress
from datetime import datetime, timedelta


class Collector(object):
    """漏洞数据采集器，获取对应日期漏洞数据的beautiful soup对象"""
    _site_title = 'SiteTitle'
    _nvd_site = 'https://nvd.nist.gov/vuln/detail/'
    days = 0
    dates = []

    def set_days(self, days=1):
        """设置采集的天数"""
        self.days = days
        self.dates = self.__get_time(days)

    @staticmethod
    def __get_time(days):
        """由输入的天数获取要采集的具体日期"""
        dates = []
        for d in range(days):
            dates.append((datetime.today() + timedelta(-d)).strftime('%Y-%m-%d'))

        return dates


class CollectCNNVD(Collector):
    """CNNVD解析器"""
    _site_title = 'CNNVD'
    _site_head = 'http://www.cnnvd.org.cn'
    _site_url = f'{_site_head}/web/vulnerability/querylist.tag'  # 国家信息安全漏洞库
    _query_url = f'{_site_head}/web/vulnerability/queryLds.tag?qcvCnnvdid='  # 根据CVE搜索CNNVD

    def get_all_simple_html(self):
        """采集所有简要数据页面"""
        print(f'* 开始采集{self._site_title}网站最近{self.days}天的漏洞数据.')
        start_time = time.time()
        simple_html = []
        for index, date in enumerate(self.dates):
            print(f'* {index + 1}.开始采集{date}的数据.')
            page_count = self.__search_page_by_date(date)
            page_data = self.__get_pages_simple_html(date, int(page_count))
            simple_html.extend(page_data)
        run_time = time.time() - start_time
        m, s = divmod(run_time, 60)
        if len(simple_html) != 0:
            print(f'\r* 最近{self.days}天的{len(simple_html)}页简要数据采集总耗时{str(int(m))}分{str(round(s))}秒.')
        return simple_html

    @staticmethod
    def get_all_detail_html(data):
        """采集所有条详情数据页面"""
        detail_html = []
        total = len(data)
        if total == 0:
            return detail_html
        print(f'* 开始采集过滤后的{total}条详细数据.')
        start_time = time.time()
        for index, d in enumerate(data):
            one_html = Soup(d[const.cnnvd_href]).html
            print_progress('正在采集详情数据', index + 1, total)
            detail_html.append(one_html)
        run_time = time.time() - start_time
        m, s = divmod(run_time, 60)
        print(f'\r* {total}条详情数据采集完成，耗时{str(int(m))}分{str(round(s))}秒.')
        return detail_html

    def get_simple_html_by_cve(self, cve_rows):
        """根据CVE编号获取所有的CNNVD简要数据"""
        html_data = []
        total = len(cve_rows)
        if total == 0:
            return html_data
        for index, row in enumerate(cve_rows):
            query_url = f'{self._query_url}{row}'
            one_html = Soup(query_url).html
            print_progress('正在采集简要数据', index, total)
            html_data.append(one_html)
        print(f'\r* {total}页简要数据采集完成.')
        return html_data

    def __search_page_by_date(self, date):
        """按日期检索数据"""
        # next_url = f'{self._site_url}?cvCnnvdUpdatedateXq={date}'
        next_url = f'http://www.cnnvd.org.cn/web/vulnerability/querylist.tag?qstartdateXq={date}'
        html = Soup(next_url).html
        div_tag = html.find('div', class_='page')
        page_count = 0
        if div_tag and div_tag.input:
            page_count = div_tag.input.get('value')
        print(f'\r* 按日期{date}检索到{page_count}页数据.')
        return page_count

    def __get_pages_simple_html(self, date, page_count):
        """采集所有页的简要数据"""
        html_data = []
        if page_count == 0:
            return html_data
        for pageno in range(1, page_count + 1):
            # next_url = f'{self._site_url}?cvCnnvdUpdatedateXq={date}&pageno={pageno}&repairLd='
            next_url = f'http://www.cnnvd.org.cn/web/vulnerability/querylist.tag?qstartdateXq={date}&pageno={pageno}&repairLd='
            one_html = Soup(next_url).html
            print_progress('正在采集简要数据', pageno, page_count)
            html_data.append(one_html)
        print(f'\r* {date}的{page_count}页简要数据采集完成.')
        return html_data

    @staticmethod
    def get_cve_score_html(data):
        """采集CVE评分数据页面"""
        cve_detail_html = []
        total = len(data)
        if total == 0:
            return cve_detail_html
        print(f'* 开始采集过滤后的{total}条CVE评分数据.')
        start_time = time.time()
        for index, d in enumerate(data):
            one_html = Soup(d[const.cve_href]).html
            print_progress('正在采集CVE评分数据', index + 1, total)
            cve_detail_html.append(one_html)
        run_time = time.time() - start_time
        m, s = divmod(run_time, 60)
        print(f'\r* {total}条CVE评分数据采集完成，耗时{str(int(m))}分{str(round(s))}秒.')
        return cve_detail_html
